{
    "queue_name": "test-japaneast-1",
    "models": [
        "optimum/gpt2",
        "facebook/mbart-large-cc25",
        "microsoft/xtremedistil-l6-h256-uncased",
        "lvwerra/gpt2-imdb",
        "uer/gpt2-chinese-cluecorpussmall",
        "databricks/dolly-v2-7b",
        "facebook/esm2_t12_35M_UR50D",
        "sdadas/mt5-base-translator-pl-en",
        "Intel/bert-base-uncased-mrpc",
        "TheBloke/airoboros-l2-70B-GPT4-2.0-GPTQ",
        "lmsys/vicuna-13b-v1.5-16k",
        "slauw87/bart_summarisation",
        "sagorsarker/codeswitch-hineng-pos-lince",
        "neulab/codebert-java",
        "tomh/toxigen_hatebert",
        "thatdramebaazguy/roberta-base-squad",
        "KoboldAI/OPT-2.7B-Erebus",
        "NousResearch/Nous-Hermes-Llama2-13b",
        "cross-encoder/stsb-roberta-large",
        "EleutherAI/pythia-1.4b-deduped",
        "bigwiz83/sapbert-from-pubmedbert-squad2",
        "ai-forever/ruBert-base",
        "reciprocate/gpt-j_rm_format-oa",
        "internlm/internlm-7b",
        "cointegrated/roberta-large-cola-krishna2020",
        "shahrukhx01/question-vs-statement-classifier",
        "cross-encoder/ms-marco-MiniLM-L-2-v2",
        "EleutherAI/polyglot-ko-12.8b",
        "hf-internal-testing/tiny-random-language_perceiver",
        "WizardLM/WizardLM-70B-V1.0",
        "Salesforce/codegen-16B-nl",
        "WizardLM/WizardLM-13B-V1.2",
        "HuggingFaceH4/tiny-random-LlamaForCausalLM"
    ],
    "workspace": "test-japaneast",
    "subscription": "80c77c76-74ba-4c8c-8229-4c3b2957990c",
    "resource_group": "huggingface-registry-test1",
    "registry": "HuggingFace",
    "environment": "automate-venv",
    "compute": "Standard-E64s-v3",
    "instance_type": "Standard_E64s_v3"
}