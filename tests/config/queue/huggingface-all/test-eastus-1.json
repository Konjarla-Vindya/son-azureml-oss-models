{
    "queue_name": "test-eastus-1",
    "models": [
        "trl-internal-testing/tiny-random-BloomForCausalLM",
        "openlm-research/open_llama_7b_v2",
        "togethercomputer/GPT-JT-6B-v1",
        "textattack/bert-base-uncased-MNLI",
        "facebook/esm1v_t33_650M_UR90S_3",
        "pszemraj/led-large-book-summary",
        "textattack/bert-base-uncased-SST-2",
        "Qwen/Qwen-VL-Chat",
        "arpanghoshal/EmoRoBERTa",
        "mosaicml/mpt-7b-chat",
        "replit/replit-code-v1-3b",
        "bigscience/bloom-1b7",
        "liuhaotian/llava-v1-0719-336px-lora-merge-vicuna-13b-v1.3",
        "stabilityai/japanese-stablelm-base-alpha-7b",
        "sagorsarker/codeswitch-hineng-ner-lince",
        "facebook/esm1v_t33_650M_UR90S_5",
        "facebook/nllb-200-distilled-1.3B",
        "edumunozsala/llama-2-7b-int4-python-code-20k",
        "cardiffnlp/twitter-roberta-base-emotion",
        "optimum/distilbert-base-uncased-finetuned-sst-2-english",
        "lvkaokao/llama2-7b-hf-chat-lora-v3",
        "climatebert/distilroberta-base-climate-sentiment",
        "kit-nlp/bert-base-japanese-sentiment-irony",
        "seyonec/PubChem10M_SMILES_BPE_450k",
        "hf-internal-testing/tiny-random-MptForCausalLM",
        "lmsys/vicuna-13b-v1.1",
        "KoboldAI/GPT-NeoX-20B-Erebus",
        "yarongef/DistilProtBert",
        "cambridgeltl/sst_mobilebert-uncased",
        "TigerResearch/tigerbot-13b-chat-v1",
        "deepset/gbert-base",
        "mosaicml/mpt-30b-instruct",
        "bigcode/starcoderbase-1b"
    ],
    "workspace": "test-eastus",
    "subscription": "80c77c76-74ba-4c8c-8229-4c3b2957990c",
    "resource_group": "huggingface-registry-test1",
    "registry": "HuggingFace",
    "environment": "automate-venv",
    "compute": "Standard-E64s-v3",
    "instance_type": "Standard_E64s_v3"
}