{
    "queue_name": "test-southcentralus-0",
    "models": [
        "SamLowe/roberta-base-go_emotions",
        "alimazhar-110/website_classification",
        "benjamin/wtp-canine-s-1l",
        "NousResearch/Llama-2-13b-hf",
        "PascalNotin/Tranception_Small",
        "ckiplab/bert-base-chinese-ner",
        "YeungNLP/firefly-baichuan-13b",
        "yiyanghkust/finbert-tone",
        "cardiffnlp/twitter-xlm-roberta-base-sentiment",
        "bhadresh-savani/distilbert-base-uncased-emotion",
        "cardiffnlp/twitter-roberta-base-offensive",
        "dbmdz/bert-large-cased-finetuned-conll03-english",
        "microsoft/mdeberta-v3-base",
        "distilbert-base-cased",
        "vblagoje/bert-english-uncased-finetuned-pos",
        "facebook/opt-1.3b",
        "syzymon/long_llama_3b",
        "meta-llama/Llama-2-7b-chat-hf",
        "bigscience/bloomz-1b1",
        "EleutherAI/pythia-6.9b",
        "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "cl-tohoku/bert-base-japanese-whole-word-masking",
        "ipuneetrathore/bert-base-cased-finetuned-finBERT",
        "klue/roberta-base",
        "tomh/toxigen_roberta",
        "fxmarty/tiny-llama-fast-tokenizer",
        "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
        "tiiuae/falcon-7b-instruct",
        "finiteautomata/bertweet-base-sentiment-analysis",
        "decapoda-research/llama-7b-hf",
        "deepset/bert-large-uncased-whole-word-masking-squad2",
        "seyonec/ChemBERTa-zinc-base-v1",
        "NousResearch/Llama-2-7b-hf",
        "kk08/CryptoBERT"
    ],
    "workspace": "test-southcentralus",
    "subscription": "80c77c76-74ba-4c8c-8229-4c3b2957990c",
    "resource_group": "huggingface-registry-test1",
    "registry": "HuggingFace",
    "environment": "automate-venv",
    "compute": "Standard-E64s-v3",
    "instance_type": "Standard_E64s_v3"
}