{
    "queue_name": "test-southcentralus-1",
    "models": [
        "cardiffnlp/twitter-roberta-base-irony",
        "Ashishkr/query_wellformedness_score",
        "microsoft/deberta-base",
        "tiiuae/falcon-7b",
        "bigscience/bloom-560m",
        "deepset/roberta-base-squad2",
        "cardiffnlp/twitter-roberta-base-sentiment-latest",
        "nlptown/bert-base-multilingual-uncased-sentiment",
        "dslim/bert-base-NER",
        "j-hartmann/emotion-english-distilroberta-base",
        "sshleifer/distilbart-cnn-12-6",
        "lvwerra/distilbert-imdb",
        "dslim/bert-large-NER",
        "cross-encoder/ms-marco-MiniLM-L-12-v2",
        "hfl/chinese-bert-wwm-ext",
        "microsoft/deberta-large-mnli",
        "dmis-lab/biobert-large-cased-v1.1-mnli",
        "hf-internal-testing/tiny-random-GPTNeoXForCausalLM",
        "hf-internal-testing/tiny-xlm-roberta",
        "huggyllama/llama-7b",
        "michiyasunaga/BioLinkBERT-base",
        "cross-encoder/ms-marco-MiniLM-L-4-v2",
        "TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ",
        "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext",
        "Qwen/Qwen-7B",
        "Seethal/sentiment_analysis_generic_dataset",
        "vinai/bertweet-base",
        "dmis-lab/biobert-base-cased-v1.2",
        "michellejieli/emotion_text_classifier",
        "Qwen/Qwen-7B-Chat",
        "meta-llama/Llama-2-70b-chat-hf",
        "amazon/FalconLite",
        "hf-internal-testing/tiny-random-OPTForCausalLM"
    ],
    "workspace": "test-southcentralus",
    "subscription": "80c77c76-74ba-4c8c-8229-4c3b2957990c",
    "resource_group": "huggingface-registry-test1",
    "registry": "HuggingFace",
    "environment": "automate-venv",
    "compute": "Standard-E64s-v3",
    "instance_type": "Standard_E64s_v3"
}