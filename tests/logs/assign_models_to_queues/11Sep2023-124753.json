{
    "test-southcentralus": {
        "0": [
            "bert-base-uncased",
            "deepset/roberta-base-squad2",
            "hfl/chinese-bert-wwm-ext",
            "TheBloke/Wizard-Vicuna-7B-Uncensored-GPTQ",
            "Geotrend/distilbert-base-en-fr-cased",
            "lmsys/vicuna-7b-v1.3",
            "vinai/phobert-base",
            "baichuan-inc/Baichuan-7B",
            "ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa",
            "neuralmind/bert-large-portuguese-cased",
            "Gryphe/MythoMax-L2-13b",
            "openlm-research/open_llama_3b_v2",
            "Helsinki-NLP/opus-mt-en-nl",
            "cyberagent/open-calm-7b",
            "TigerResearch/tigerbot-13b-chat-v1",
            "mosaicml/mpt-30b-chat",
            "WizardLM/WizardCoder-15B-V1.0",
            "cointegrated/roberta-large-cola-krishna2020",
            "facebook/galactica-125m",
            "mrsinghania/asr-question-detection",
            "TheBloke/Llama-2-7B-GPTQ",
            "TheBloke/WizardLM-7B-uncensored-GPTQ",
            "indolem/indobert-base-uncased",
            "decapoda-research/llama-30b-hf",
            "Helsinki-NLP/opus-mt-ko-en",
            "TypicaAI/magbert-ner",
            "plguillou/t5-base-fr-sum-cnndm",
            "TheBloke/WizardCoder-15B-1.0-GPTQ",
            "klue/roberta-small"
        ],
        "1": [
            "gpt2",
            "baichuan-inc/Baichuan-13B-Base",
            "cl-tohoku/bert-base-japanese",
            "facebook/opt-125m",
            "skt/kogpt2-base-v2",
            "sasha/regardv3",
            "uer/albert-base-chinese-cluecorpussmall",
            "HuggingFaceH4/starchat-beta",
            "albert-base-v1",
            "nbroad/ESG-BERT",
            "pdelobelle/robbert-v2-dutch-base",
            "nlp04/korean_sentiment_analysis_kcelectra",
            "julien-c/dummy-unknown",
            "optimum/distilbert-base-uncased-finetuned-sst-2-english",
            "textattack/bert-base-uncased-CoLA",
            "Helsinki-NLP/opus-mt-no-de",
            "onlplab/alephbert-base",
            "deepset/gelectra-large-germanquad",
            "cross-encoder/stsb-distilroberta-base",
            "seyonec/PubChem10M_SMILES_BPE_60k",
            "TheBloke/Llama-2-70B-fp16",
            "Helsinki-NLP/opus-mt-en-it",
            "Salesforce/xgen-7b-8k-base",
            "Deci/DeciCoder-1b",
            "cross-encoder/quora-distilroberta-base",
            "stabilityai/stablelm-tuned-alpha-7b",
            "cardiffnlp/camembert-base-tweet-sentiment-fr",
            "songlab/gpn-brassicales",
            "InstaDeepAI/nucleotide-transformer-500m-human-ref"
        ],
        "2": [
            "xlm-roberta-base",
            "distilgpt2",
            "Helsinki-NLP/opus-mt-en-es",
            "roberta-base-openai-detector",
            "NousResearch/Llama-2-7b-hf",
            "KoboldAI/OPT-6B-nerys-v2",
            "dbmdz/bert-base-german-uncased",
            "rajpurkarlab/gilbert",
            "apanc/russian-inappropriate-messages",
            "zhihan1996/DNA_bert_6",
            "TheBloke/Llama-2-70B-chat-GPTQ",
            "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
            "soleimanian/financial-roberta-large-sentiment",
            "microsoft/deberta-v3-small",
            "salti/bert-base-multilingual-cased-finetuned-squad",
            "bigcode/gpt_bigcode-santacoder",
            "KoboldAI/OPT-2.7B-Erebus",
            "neulab/codebert-javascript",
            "TheBloke/falcon-40b-instruct-GPTQ",
            "ALINEAR/albert-japanese-v2",
            "sbcBI/sentiment_analysis",
            "garage-bAInd/Platypus2-70B-instruct",
            "facebook/incoder-1B",
            "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v2",
            "AdamG012/chat-opt-350m-reward-deepspeed",
            "naver/splade_v2_distil",
            "dbmdz/bert-base-italian-xxl-cased",
            "ziqingyang/chinese-alpaca-2-7b",
            "pszemraj/long-t5-tglobal-base-16384-booksci-summary-v1"
        ],
        "3": [
            "SamLowe/roberta-base-go_emotions",
            "YeungNLP/firefly-baichuan-13b",
            "gpt2-xl",
            "airesearch/wangchanberta-base-att-spm-uncased",
            "hf-internal-testing/tiny-random-OPTForCausalLM",
            "EleutherAI/gpt-neox-20b",
            "samayash/finetuning-financial-news-sentiment",
            "textattack/distilbert-base-cased-CoLA",
            "Gustavosta/MagicPrompt-Stable-Diffusion",
            "pedramyazdipoor/persian_xlm_roberta_large",
            "distilbert-base-german-cased",
            "TigerResearch/tigerbot-13b-chat",
            "mosaicml/mpt-7b-chat",
            "assemblyai/distilbert-base-uncased-sst2",
            "deepset/gbert-base",
            "Helsinki-NLP/opus-mt-gmw-gmw",
            "sagorsarker/bangla-bert-base",
            "shahrukhx01/question-vs-statement-classifier",
            "zhihan1996/DNABERT-2-117M",
            "AdamG012/chat-opt-1.3b-sft-deepspeed",
            "timpal0l/mdeberta-v3-base-squad2",
            "AUTOMATIC/promptgen-lexart",
            "deepset/gelectra-base-germanquad",
            "elyza/ELYZA-japanese-Llama-2-7b-instruct",
            "JasperLS/gelectra-base-injection",
            "beomi/KoAlpaca-Polyglot-5.8B",
            "WeOpenML/PandaLM-7B-v1",
            "daryl149/llama-2-13b-chat-hf",
            "nandwalritik/sql_classifier"
        ],
        "4": [
            "distilbert-base-uncased",
            "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "facebook/opt-1.3b",
            "klue/roberta-base",
            "microsoft/infoxlm-large",
            "meta-llama/Llama-2-13b-hf",
            "deepset/tinyroberta-squad2",
            "google/pegasus-cnn_dailymail",
            "bert-base-german-dbmdz-uncased",
            "cardiffnlp/twitter-roberta-base-hate-latest",
            "Helsinki-NLP/opus-mt-en-ru",
            "Helsinki-NLP/opus-mt-ine-en",
            "microsoft/deberta-v3-xsmall",
            "lvkaokao/llama2-7b-hf-chat-lora-v3",
            "lmsys/vicuna-33b-v1.3",
            "sdadas/mt5-base-translator-pl-en",
            "albert-large-v2",
            "fxmarty/tiny-mpt-random-remote-code",
            "bigcode/starpii",
            "Helsinki-NLP/opus-mt-de-ar",
            "anferico/bert-for-patents",
            "Phind/Phind-CodeLlama-34B-v1",
            "Helsinki-NLP/opus-mt-en-fi",
            "dbmdz/bert-base-italian-cased",
            "internlm/internlm-chat-7b-8k",
            "arbazk/maestroqa-distilbert-negative-sentiment",
            "abeja/gpt-neox-japanese-2.7b",
            "google/bert2bert_L-24_wmt_de_en",
            "tau/splinter-base"
        ]
    },
    "test-eastus": {
        "0": [
            "cardiffnlp/twitter-roberta-base-irony",
            "emilyalsentzer/Bio_ClinicalBERT",
            "microsoft/deberta-large-mnli",
            "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext",
            "kk08/CryptoBERT",
            "facebook/opt-350m",
            "upstage/SOLAR-0-70b-16bit",
            "openlm-research/open_llama_13b",
            "xlnet-large-cased",
            "facebook/wmt19-de-en",
            "KB/bert-base-swedish-cased",
            "Helsinki-NLP/opus-mt-ja-en",
            "cross-encoder/ms-marco-TinyBERT-L-2",
            "EleutherAI/polyglot-ko-1.3b",
            "bigscience/bloom-1b1",
            "ai-forever/mGPT",
            "sshleifer/tiny-dbmdz-bert-large-cased-finetuned-conll03-english",
            "Helsinki-NLP/opus-mt-tc-big-ar-en",
            "transfo-xl-wt103",
            "vlrfrwaprnyysf1/vKUFUzrUTxZmKaL",
            "eachadea/vicuna-13b-1.1",
            "j-hartmann/sentiment-roberta-large-english-3-classes",
            "OpenAssistant/llama2-13b-orca-8k-3319",
            "flaubert/flaubert_small_cased",
            "bigcode/starcoderplus",
            "mosaicml/mpt-7b-8k-instruct",
            "Geotrend/distilbert-base-es-cased",
            "aubmindlab/bert-base-arabertv02-twitter",
            "hidude562/Wiki-Complexity"
        ],
        "1": [
            "roberta-base",
            "yiyanghkust/finbert-tone",
            "stabilityai/StableBeluga2",
            "distilbert-base-cased-distilled-squad",
            "neuralmind/bert-base-portuguese-cased",
            "Helsinki-NLP/opus-mt-pl-en",
            "microsoft/deberta-xlarge-mnli",
            "optimum/t5-small",
            "sshleifer/tiny-distilroberta-base",
            "Helsinki-NLP/opus-mt-sv-en",
            "facebook/opt-13b",
            "trl-internal-testing/tiny-random-CodeGenForCausalLM",
            "replit/replit-code-v1-3b",
            "elinas/chronos-13b-v2",
            "mosaicml/mpt-30b-instruct",
            "deepset/roberta-base-squad2-distilled",
            "NousResearch/Nous-Hermes-Llama2-13b",
            "cross-encoder/ms-marco-MiniLM-L-2-v2",
            "Helsinki-NLP/opus-mt-tc-big-en-ar",
            "Salesforce/codegen-350M-multi",
            "beomi/kykim-gpt3-kor-small_based_on_gpt2",
            "TheBloke/StableBeluga-7B-GPTQ",
            "etalab-ia/camembert-base-squadFR-fquad-piaf",
            "scite/ms-marco-MiniLM-L-12-v2-onnx-optimized",
            "MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c",
            "codellama/CodeLlama-7b-Python-hf",
            "human-centered-summarization/financial-summarization-pegasus",
            "roneneldan/TinyStories-33M",
            "nlpaueb/bert-base-greek-uncased-v1"
        ],
        "2": [
            "albert-base-v2",
            "nlptown/bert-base-multilingual-uncased-sentiment",
            "syzymon/long_llama_3b",
            "philschmid/bart-large-cnn-samsum",
            "hf-internal-testing/tiny-random-GPTJForCausalLM",
            "HooshvareLab/bert-base-parsbert-ner-uncased",
            "Babelscape/wikineural-multilingual-ner",
            "deepset/bert-base-cased-squad2",
            "Salesforce/codegen-350M-mono",
            "codellama/CodeLlama-7b-hf",
            "KoboldAI/OPT-13B-Nerys-v2",
            "trl-internal-testing/tiny-random-GPTJForCausalLM",
            "facebook/esm2_t36_3B_UR50D",
            "climatebert/distilroberta-base-climate-sentiment",
            "julien-c/bert-xsmall-dummy",
            "Intel/bert-base-uncased-mrpc",
            "FredZhang7/distilgpt2-stable-diffusion-v2",
            "EMBEDDIA/sloberta",
            "ctrl",
            "cis-lmu/glot500-base",
            "ai-forever/rugpt3large_based_on_gpt2",
            "succinctly/text2image-prompt-generator",
            "monologg/kobigbird-bert-base",
            "OpenMatch/cocodr-base-msmarco",
            "KoboldAI/GPT-Neo-2.7B-Janeway",
            "TheBloke/WizardLM-1.0-Uncensored-Llama2-13B-GPTQ",
            "bigscience/bloomz-7b1-mt",
            "jondurbin/airoboros-13b-gpt4-1.4",
            "cointegrated/rubert-tiny"
        ],
        "3": [
            "marieke93/MiniLM-evidence-types",
            "facebook/bart-large-cnn",
            "dmis-lab/biobert-large-cased-v1.1-mnli",
            "tomh/toxigen_roberta",
            "xlnet-base-cased",
            "ynie/roberta-large-snli_mnli_fever_anli_R1_R2_R3-nli",
            "ml6team/keyphrase-extraction-distilbert-inspec",
            "lxyuan/distilbert-base-multilingual-cased-sentiments-student",
            "ml6team/keyphrase-extraction-kbir-inspec",
            "Helsinki-NLP/opus-mt-tr-en",
            "Helsinki-NLP/opus-mt-id-en",
            "trl-internal-testing/tiny-random-GPTNeoForCausalLM",
            "facebook/wmt19-en-de",
            "cl-tohoku/bert-base-japanese-v2",
            "huggingface/CodeBERTa-language-id",
            "d4data/biomedical-ner-all",
            "Helsinki-NLP/opus-mt-th-en",
            "ai4bharat/IndicBERTv2-MLM-only",
            "cross-encoder/stsb-TinyBERT-L-4",
            "UBC-NLP/MARBERTv2",
            "cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual",
            "google/electra-small-generator",
            "tblard/tf-allocine",
            "kssteven/ibert-roberta-base",
            "IDEA-CCNL/Erlangshen-Roberta-110M-NLI",
            "mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es",
            "microsoft/Multilingual-MiniLM-L12-H384",
            "nlpaueb/bert-base-uncased-contracts",
            "Qwen/Qwen-VL"
        ],
        "4": [
            "alimazhar-110/website_classification",
            "cardiffnlp/twitter-xlm-roberta-base-sentiment",
            "bert-base-multilingual-uncased",
            "Qwen/Qwen-7B",
            "oliverguhr/german-sentiment-bert",
            "cointegrated/rubert-tiny-toxicity",
            "Rakib/roberta-base-on-cuad",
            "flaubert/flaubert_base_cased",
            "deepset/deberta-v3-base-squad2",
            "Einmalumdiewelt/T5-Base_GNAD",
            "facebook/wmt19-ru-en",
            "Jean-Baptiste/camembert-ner-with-dates",
            "bigscience/bloom-1b7",
            "ElKulako/cryptobert",
            "bigcode/starcoderbase-1b",
            "csdc-atl/baichuan-7B-chat",
            "ybelkada/falcon-7b-sharded-bf16",
            "ku-nlp/deberta-v2-tiny-japanese-char-wwm",
            "stabilityai/japanese-stablelm-instruct-alpha-7b",
            "rinna/japanese-gpt-neox-3.6b-instruction-ppo",
            "beomi/llama-2-ko-7b",
            "bert-base-cased-finetuned-mrpc",
            "togethercomputer/RedPajama-INCITE-Base-3B-v1",
            "hfl/chinese-bert-wwm",
            "amberoad/bert-multilingual-passage-reranking-msmarco",
            "wonrax/phobert-base-vietnamese-sentiment",
            "marefa-nlp/marefa-ner",
            "KoboldAI/fairseq-dense-2.7B-Nerys",
            "RashidNLP/NER-Deberta"
        ]
    },
    "test-northeurope": {
        "0": [
            "Ashishkr/query_wellformedness_score",
            "dslim/bert-base-NER",
            "meta-llama/Llama-2-7b-hf",
            "sshleifer/tiny-gpt2",
            "Jean-Baptiste/roberta-large-ner-english",
            "lmsys/vicuna-13b-delta-v0",
            "koheiduck/bert-japanese-finetuned-sentiment",
            "facebook/esm1v_t33_650M_UR90S_1",
            "papluca/xlm-roberta-base-language-detection",
            "sbcBI/sentiment_analysis_model",
            "shibing624/macbert4csc-base-chinese",
            "trl-internal-testing/tiny-random-BloomForCausalLM",
            "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
            "Helsinki-NLP/opus-mt-hi-en",
            "yahma/llama-7b-hf",
            "TheBloke/airoboros-l2-70B-GPT4-2.0-GPTQ",
            "cross-encoder/stsb-roberta-large",
            "EleutherAI/polyglot-ko-12.8b",
            "The-Face-Of-Goonery/Huginn-13b-v1.2",
            "staka/fugumt-en-ja",
            "Helsinki-NLP/opus-mt-de-nl",
            "nickmuchi/quantized-optimum-finbert-tone",
            "malduwais/distilbert-base-uncased-finetuned-ner",
            "WizardLM/WizardCoder-Python-13B-V1.0",
            "akdeniz27/bert-base-turkish-cased-ner",
            "rinna/bilingual-gpt-neox-4b",
            "noamwies/llama-test-gqa-with-better-transformer",
            "bigscience/bloomz-1b7",
            "kykim/gpt3-kor-small_based_on_gpt2"
        ],
        "1": [
            "bert-base-cased",
            "dslim/bert-base-NER-uncased",
            "meta-llama/Llama-2-7b-chat-hf",
            "fxmarty/tiny-llama-fast-tokenizer",
            "ckiplab/bert-base-chinese",
            "finiteautomata/bertweet-base-emotion-analysis",
            "hf-internal-testing/tiny-random-distilbert",
            "StanfordAIMI/stanford-deidentifier-base",
            "lmsys/vicuna-13b-v1.3",
            "vinai/phobert-base-v2",
            "facebook/nllb-200-1.3B",
            "trl-internal-testing/tiny-random-OPTForCausalLM",
            "Helsinki-NLP/opus-mt-ROMANCE-en",
            "kit-nlp/bert-base-japanese-sentiment-irony",
            "Rostlab/prot_bert_bfd",
            "xlm-roberta-large-finetuned-conll03-english",
            "felflare/bert-restore-punctuation",
            "benjamin/wtp-bert-mini",
            "dbmdz/bert-base-german-cased",
            "ncfrey/ChemGPT-4.7M",
            "microsoft/BiomedVLP-CXR-BERT-specialized",
            "stevhliu/my_awesome_model",
            "bigscience/bigscience-small-testing",
            "cactusfriend/nightmare-promptgen-XL",
            "lamini/lamini_docs_finetuned",
            "Elron/bleurt-tiny-512",
            "TigerResearch/tigerbot-13b-base",
            "HuggingFaceM4/idefics-80b-instruct",
            "Salesforce/codegen-16B-multi"
        ],
        "2": [
            "vinai/xphonebert-base",
            "Jean-Baptiste/camembert-ner",
            "Helsinki-NLP/opus-mt-ar-en",
            "Seethal/sentiment_analysis_generic_dataset",
            "bert-large-cased",
            "SAPOSS/password-model",
            "Maykeye/TinyLLama-v0",
            "KoboldAI/GPT-J-6B-Janeway",
            "HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary",
            "OpenAssistant/reward-model-deberta-v3-large-v2",
            "cardiffnlp/tweet-topic-21-multi",
            "trl-internal-testing/tiny-random-CodeGenForCausalLM-sharded",
            "obi/deid_roberta_i2b2",
            "hatmimoha/arabic-ner",
            "TheBloke/vicuna-7B-v1.3-GPTQ",
            "cross-encoder/ms-marco-electra-base",
            "Helsinki-NLP/opus-mt-ca-en",
            "EleutherAI/pythia-410m",
            "sambanovasystems/BLOOMChat-176B-v1",
            "Helsinki-NLP/opus-mt-ar-de",
            "facebook/xmod-base",
            "stabilityai/stablelm-tuned-alpha-3b",
            "psmathur/orca_mini_v3_70b",
            "pszemraj/long-t5-tglobal-base-16384-book-summary",
            "TheBloke/WizardLM-33B-V1.0-Uncensored-GPTQ",
            "google/bigbird-base-trivia-itc",
            "xlm-mlm-en-2048",
            "lmsys/longchat-7b-v1.5-32k",
            "explosion-testing/llama2-fewer-kv-heads"
        ],
        "3": [
            "benjamin/wtp-canine-s-1l",
            "bhadresh-savani/distilbert-base-uncased-emotion",
            "hf-internal-testing/tiny-random-GPTNeoXForCausalLM",
            "EleutherAI/gpt-j-6b",
            "monologg/koelectra-small-v2-distilled-korquad-384",
            "klue/bert-base",
            "facebook/esm2_t33_650M_UR50D",
            "mdhugol/indonesia-bert-sentiment-classification",
            "beomi/kcbert-base",
            "cardiffnlp/twitter-roberta-base-hate",
            "Helsinki-NLP/opus-mt-da-en",
            "openlm-research/open_llama_7b_v2",
            "liuhaotian/llava-v1-0719-336px-lora-merge-vicuna-13b-v1.3",
            "flaubert/flaubert_base_uncased",
            "m3hrdadfi/typo-detector-distilbert-en",
            "bert-large-cased-whole-word-masking-finetuned-squad",
            "rvrtdta/roberta-base-bne-finetuned-MeIA-AnalisisDeSentimientos",
            "hf-internal-testing/tiny-random-language_perceiver",
            "ssbuild/baichuan-13b-chat-int4",
            "KoboldAI/LLaMA2-13B-Holomax-GPTQ",
            "ku-nlp/deberta-v2-tiny-japanese",
            "rajkumarrrk/gpt2-fine-tuned-on-imdb-positive-reviews",
            "microsoft/deberta-v2-xlarge-mnli",
            "ahmedrachid/FinancialBERT-Sentiment-Analysis",
            "roneneldan/TinyStories-1M",
            "HuggingFaceM4/idefics-9b-instruct",
            "NousResearch/Llama-2-13b-chat-hf",
            "michiyasunaga/BioLinkBERT-large",
            "abnersampaio/sentiment"
        ],
        "4": [
            "microsoft/deberta-base",
            "j-hartmann/emotion-english-distilroberta-base",
            "Helsinki-NLP/opus-mt-zh-en",
            "madhurjindal/autonlp-Gibberish-Detector-492513457",
            "hf-internal-testing/tiny-random-GPTBigCodeForCausalLM",
            "prithivida/parrot_adequacy_model",
            "Helsinki-NLP/opus-mt-nl-en",
            "facebook/nllb-200-distilled-600M",
            "facebook/roberta-hate-speech-dynabench-r4-target",
            "Phind/Phind-CodeLlama-34B-Python-v1",
            "MarcBrun/ixambert-finetuned-squad-eu-en",
            "ckiplab/albert-tiny-chinese-ws",
            "deepset/minilm-uncased-squad2",
            "seyonec/PubChem10M_SMILES_BPE_450k",
            "optimum/gpt2",
            "togethercomputer/RedPajama-INCITE-Chat-3B-v1",
            "EleutherAI/pythia-1.4b-deduped",
            "KM4STfulltext/SSCI-SciBERT-e2",
            "TheBloke/Llama-2-13B-GPTQ",
            "s-nlp/roberta_toxicity_classifier",
            "it5/it5-base-news-summarization",
            "cnut1648/biolinkbert-large-mnli-snli",
            "google/reformer-crime-and-punishment",
            "nlpaueb/sec-bert-base",
            "cerebras/Cerebras-GPT-111M",
            "eachadea/vicuna-7b-1.1",
            "yangheng/deberta-v3-base-absa-v1.1",
            "OpenAssistant/falcon-7b-sft-top1-696",
            "KoboldAI/GPT-J-6B-Shinen"
        ]
    },
    "test-japaneast": {
        "0": [
            "bert-base-multilingual-cased",
            "t5-large",
            "Helsinki-NLP/opus-mt-en-zh",
            "microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract",
            "tner/roberta-large-ontonotes5",
            "Helsinki-NLP/opus-mt-tc-big-en-pt",
            "Hello-SimpleAI/chatgpt-detector-roberta-chinese",
            "dccuchile/bert-base-spanish-wwm-uncased",
            "s-nlp/roberta-base-formality-ranker",
            "ufal/robeczech-base",
            "neulab/codebert-python",
            "hf-internal-testing/tiny-bert-for-token-classification",
            "facebook/opt-30b",
            "bigscience/bloomz-560m",
            "google/pegasus-large",
            "lmsys/vicuna-13b-v1.5-16k",
            "MilaNLProc/feel-it-italian-emotion",
            "databricks/dolly-v2-12b",
            "jplu/tf-camembert-base",
            "facebook/xglm-564M",
            "Helsinki-NLP/opus-mt-en-da",
            "Aniemore/rubert-large-emotion-russian-cedr-m7",
            "uer/chinese_roberta_L-2_H-128",
            "Helsinki-NLP/opus-mt-es-fr",
            "defog/sqlcoder",
            "moussaKam/barthez-sentiment-classification",
            "liuhaotian/llava-llama-2-13b-chat-lightning-preview",
            "uw-madison/yoso-4096",
            "explosion-testing/mpt-test"
        ],
        "1": [
            "distilbert-base-multilingual-cased",
            "Helsinki-NLP/opus-mt-fr-en",
            "cross-encoder/ms-marco-TinyBERT-L-2-v2",
            "vinai/bertweet-base",
            "deepset/electra-base-squad2",
            "gilf/french-camembert-postag-model",
            "Helsinki-NLP/opus-mt-mul-en",
            "t5-3b",
            "EleutherAI/pythia-70m-deduped",
            "textattack/albert-base-v2-ag-news",
            "jackaduma/SecBERT",
            "togethercomputer/GPT-JT-6B-v1",
            "stabilityai/japanese-stablelm-base-alpha-7b",
            "ahotrod/electra_large_discriminator_squad2_512",
            "cerebras/Cerebras-GPT-13B",
            "s-nlp/russian_toxicity_classifier",
            "TheTravellingEngineer/llama2-7b-hf-guanaco",
            "WizardLM/WizardLM-70B-V1.0",
            "Helsinki-NLP/opus-mt-en-ar",
            "TheBloke/Llama-2-7B-32K-Instruct-GPTQ",
            "rinna/japanese-gpt2-medium",
            "EleutherAI/pythia-1b",
            "Helsinki-NLP/opus-mt-nl-fr",
            "mdraw/german-news-sentiment-bert",
            "codellama/CodeLlama-13b-Python-hf",
            "mrm8488/bert-medium-finetuned-squadv2",
            "TigerResearch/tigerbot-13b-base-v1",
            "abhishek/llama-2-7b-hf-small-shards",
            "Open-Orca/OpenOrcaxOpenChat-Preview2-13B"
        ],
        "2": [
            "bert-base-chinese",
            "martin-ha/toxic-comment-model",
            "bigscience/bloomz-1b1",
            "PlanTL-GOB-ES/roberta-base-bne",
            "apanc/russian-sensitive-topics",
            "facebook/nllb-200-3.3B",
            "Hello-SimpleAI/chatgpt-detector-roberta",
            "daryl149/llama-2-7b-chat-hf",
            "sshleifer/distilbart-xsum-12-6",
            "classla/bcms-bertic-ner",
            "monologg/koelectra-base-v3-generator",
            "deepset/roberta-large-squad2",
            "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1",
            "bigscience/bloom-3b",
            "Helsinki-NLP/opus-mt-fr-de",
            "bigcode/santacoder",
            "citizenlab/distilbert-base-multilingual-cased-toxicity",
            "openbmb/cpm-ant-10b",
            "facebook/galactica-1.3b",
            "Helsinki-NLP/opus-mt-en-hu",
            "TheBloke/Wizard-Vicuna-13B-Uncensored-GPTQ",
            "hf-internal-testing/test-two-configs",
            "TheBloke/WizardLM-13B-V1.2-GPTQ",
            "internlm/internlm-chat-7b",
            "jplu/tf-xlm-roberta-base",
            "saibo/legal-roberta-base",
            "facebook/mbart-large-en-ro",
            "IMSyPP/hate_speech_en",
            "launch/POLITICS"
        ],
        "3": [
            "distilbert-base-uncased-finetuned-sst-2-english",
            "cardiffnlp/twitter-roberta-base-offensive",
            "hf-internal-testing/tiny-xlm-roberta",
            "microsoft/deberta-v3-base",
            "kredor/punctuate-all",
            "yiyanghkust/finbert-esg",
            "bert-large-uncased-whole-word-masking",
            "deepset/xlm-roberta-large-squad2",
            "ai-forever/ruGPT-3.5-13B",
            "bigscience/bloom-7b1",
            "joeddav/distilbert-base-uncased-go-emotions-student",
            "mosaicml/mpt-30b",
            "WizardLM/WizardCoder-Python-34B-V1.0",
            "hf-internal-testing/tiny-random-MptForCausalLM",
            "facebook/mbart-large-cc25",
            "Helsinki-NLP/opus-mt-fi-de",
            "Helsinki-NLP/opus-mt-bat-en",
            "mosaicml/mpt-7b-8k",
            "csarron/mobilebert-uncased-squad-v2",
            "h2oai/h2ogpt-4096-llama2-7b-chat",
            "google/muril-base-cased",
            "TheBloke/Llama-2-7B-Chat-GGML",
            "nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large",
            "trl-internal-testing/tiny-random-LlamaForCausalLM",
            "jphme/Llama-2-13b-chat-german",
            "MichaelOrme/Paraphrased_Sentence",
            "gooohjy/suicidal-electra",
            "qilowoq/AbLang_heavy",
            "julien-c/dummy-diff-tokenizer"
        ],
        "4": [
            "roberta-large",
            "sshleifer/distilbart-cnn-12-6",
            "facebook/esm2_t6_8M_UR50D",
            "tiiuae/falcon-7b-instruct",
            "huggingface/CodeBERTa-small-v1",
            "siebert/sentiment-roberta-large-english",
            "bert-large-uncased-whole-word-masking-finetuned-squad",
            "trl-internal-testing/tiny-random-GPTNeoXForCausalLM",
            "wajidlinux99/gibberish-text-detector",
            "KoboldAI/fairseq-dense-13B-Janeway",
            "trl-internal-testing/tiny-random-GPT2LMHeadModel",
            "textattack/bert-base-uncased-MNLI",
            "Helsinki-NLP/opus-mt-gem-gem",
            "GroNLP/bert-base-dutch-cased",
            "raynardj/ner-disease-ncbi-bionlp-bc5cdr-pubmed",
            "sagorsarker/codeswitch-hineng-lid-lince",
            "bigwiz83/sapbert-from-pubmedbert-squad2",
            "HooshvareLab/bert-fa-base-uncased",
            "Davlan/afro-xlmr-large-29L",
            "KoboldAI/LLaMA2-13B-Holomax",
            "cardiffnlp/twitter-roberta-base",
            "codellama/CodeLlama-13b-Instruct-hf",
            "EleutherAI/pythia-160m-deduped",
            "cointegrated/rubert-tiny2-cedr-emotion-detection",
            "blanchefort/rubert-base-cased-sentiment-rusentiment",
            "MichaelOrme/Paraphrased_Word",
            "Salesforce/codegen25-7b-multi",
            "nlpai-lab/kullm-polyglot-5.8b-v2",
            "TheBloke/vicuna-13B-v1.5-16K-GPTQ"
        ]
    },
    "test-northcentralus": {
        "0": [
            "camembert-base",
            "facebook/opt-6.7b",
            "EleutherAI/pythia-6.9b",
            "dmis-lab/biobert-base-cased-v1.2",
            "ckiplab/bert-base-chinese-ws",
            "Helsinki-NLP/opus-mt-it-en",
            "Helsinki-NLP/opus-mt-en-id",
            "bhadresh-savani/bert-base-go-emotion",
            "ckiplab/bert-base-chinese-pos",
            "EleutherAI/pythia-160m",
            "adamc-7/distilbert-imdb-micro",
            "thu-coai/roberta-base-cold",
            "sagorsarker/codeswitch-hineng-ner-lince",
            "csarron/bert-base-uncased-squad-v1",
            "tner/roberta-large-bionlp2004",
            "slauw87/bart_summarisation",
            "sociocom/MedNER-CR-JA",
            "Salesforce/codegen-16B-nl",
            "csebuetnlp/mT5_multilingual_XLSum",
            "asafaya/bert-base-arabic",
            "mosaicml/mpt-7b-storywriter",
            "uw-madison/mra-base-512-4",
            "Helsinki-NLP/opus-mt-et-en",
            "hfl/chinese-roberta-wwm-ext-large",
            "yiyanghkust/finbert-pretrain",
            "MichaelOrme/Profane",
            "line-corporation/line-distilbert-base-japanese",
            "stanford-crfm/BioMedLM"
        ],
        "1": [
            "Davlan/distilbert-base-multilingual-cased-ner-hrl",
            "dbmdz/bert-large-cased-finetuned-conll03-english",
            "huggyllama/llama-7b",
            "TheBloke/Llama-2-70B-GPTQ",
            "OpenAssistant/falcon-7b-sft-mix-2000",
            "EleutherAI/gpt-neo-2.7B",
            "openai-gpt",
            "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v3",
            "Lurunchik/nf-cats",
            "togethercomputer/Llama-2-7B-32K-Instruct",
            "xverse/XVERSE-13B-Chat",
            "neulab/codebert-cpp",
            "albert-xxlarge-v2",
            "xlm-clm-ende-1024",
            "microsoft/xtremedistil-l6-h256-uncased",
            "vilsonrodrigues/falcon-7b-instruct-sharded",
            "t5-11b",
            "stabilityai/StableBeluga-13B",
            "h2oai/h2ogpt-4096-llama2-13b-chat",
            "Qwen/Qwen-7B-Chat-Int4",
            "KB/bert-base-swedish-cased-ner",
            "TheBloke/Nous-Hermes-13B-GPTQ",
            "cardiffnlp/roberta-large-tweet-topic-single-all",
            "ilovebots/bert-sdg-french",
            "iarfmoose/bert-base-cased-qa-evaluator",
            "MichaelOrme/Profane_Removed",
            "law-ai/InLegalBERT",
            "nickmuchi/finbert-tone-finetuned-finance-topic-classification"
        ],
        "2": [
            "distilroberta-base",
            "lvwerra/distilbert-imdb",
            "ai4bharat/IndicNER",
            "finiteautomata/bertweet-base-sentiment-analysis",
            "cl-tohoku/bert-base-japanese-char",
            "meta-llama/Llama-2-70b-hf",
            "petals-team/StableBeluga2",
            "prithivida/parrot_fluency_model",
            "kykim/bert-kor-base",
            "microsoft/deberta-large",
            "cl-tohoku/bert-base-japanese-char-v2",
            "facebook/esm1v_t33_650M_UR90S_3",
            "codellama/CodeLlama-7b-Instruct-hf",
            "textattack/albert-base-v2-rotten_tomatoes",
            "emilyalsentzer/Bio_Discharge_Summary_BERT",
            "Salesforce/codegen-350M-nl",
            "xlm-mlm-100-1280",
            "EleutherAI/pythia-2.8b-deduped",
            "Sigma/financial-sentiment-analysis",
            "knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI",
            "Helsinki-NLP/opus-mt-cs-en",
            "allenai/longformer-large-4096-finetuned-triviaqa",
            "matsuo-lab/weblab-10b-instruction-sft",
            "rinna/japanese-gpt-1b",
            "LiYuan/amazon-review-sentiment-analysis",
            "Helsinki-NLP/opus-mt-gmq-en",
            "OpenAssistant/pythia-12b-sft-v8-7k-steps",
            "microsoft/deberta-xlarge"
        ],
        "3": [
            "QCRI/bert-base-multilingual-cased-pos-english",
            "cardiffnlp/twitter-roberta-base-sentiment",
            "cross-encoder/ms-marco-MiniLM-L-6-v2",
            "michellejieli/emotion_text_classifier",
            "HooshvareLab/bert-base-parsbert-uncased",
            "tsmatz/xlm-roberta-ner-japanese",
            "TheBloke/Llama-2-13B-chat-GPTQ",
            "facebook/opt-2.7b",
            "Austism/chronos-hermes-13b",
            "openlm-research/open_llama_3b",
            "Rostlab/prot_bert",
            "ckiplab/albert-tiny-chinese-pos",
            "TinyPixel/Llama-2-7B-bf16-sharded",
            "lmsys/vicuna-13b-v1.1",
            "TheBloke/Llama-2-7b-chat-fp16",
            "sagorsarker/codeswitch-hineng-pos-lince",
            "knkarthick/bart-large-xsum-samsum",
            "WizardLM/WizardLM-13B-V1.2",
            "DeepChem/ChemBERTa-77M-MLM",
            "bvanaken/clinical-assertion-negation-bert",
            "pierreguillou/bert-base-cased-squad-v1.1-portuguese",
            "knkarthick/Sentiment-Analysis",
            "ai-forever/rugpt3small_based_on_gpt2",
            "TheBloke/Llama-2-70B-Chat-fp16",
            "Salesforce/codegen-2B-mono",
            "dbmdz/bert-base-italian-uncased",
            "upstage/llama-30b-instruct-2048",
            "ehartford/WizardLM-7B-Uncensored"
        ],
        "4": [
            "NousResearch/Llama-2-13b-hf",
            "microsoft/mdeberta-v3-base",
            "EleutherAI/gpt-neo-1.3B",
            "mosaicml/mpt-7b",
            "ai-forever/ruRoberta-large",
            "dbmdz/electra-large-discriminator-finetuned-conll03-english",
            "Helsinki-NLP/opus-mt-en-de",
            "dccuchile/bert-base-spanish-wwm-cased",
            "bigcode/starcoder",
            "TheBloke/OpenAssistant-Llama2-13B-Orca-v2-8K-3166-GPTQ",
            "unitary/toxic-bert",
            "facebook/esm1v_t33_650M_UR90S_2",
            "facebook/esm1v_t33_650M_UR90S_5",
            "decapoda-research/llama-13b-hf",
            "lvwerra/gpt2-imdb",
            "TheBloke/OpenOrca-Platypus2-13B-GPTQ",
            "Helsinki-NLP/opus-mt-uk-en",
            "indigo-ai/BERTino",
            "NousResearch/Llama-2-70b-hf",
            "EleutherAI/pythia-410m-deduped",
            "Jorgeutd/bert-large-uncased-finetuned-ner",
            "DDDSSS/translation_en-zh",
            "google/bigbird-pegasus-large-arxiv",
            "NousResearch/Llama-2-70b-chat-hf",
            "cyberagent/open-calm-1b",
            "cerebras/Cerebras-GPT-1.3B",
            "Helsinki-NLP/opus-mt-zls-en",
            "aubmindlab/bert-base-arabertv2"
        ]
    },
    "test-norwayeast": {
        "0": [
            "tiiuae/falcon-7b",
            "dslim/bert-large-NER",
            "Helsinki-NLP/opus-mt-ru-en",
            "decapoda-research/llama-7b-hf",
            "nferruz/ProtGPT2",
            "nlpaueb/legal-bert-small-uncased",
            "microsoft/biogpt",
            "Helsinki-NLP/opus-mt-en-fr",
            "elastic/distilbert-base-cased-finetuned-conll03-english",
            "nlpai-lab/kullm-polyglot-12.8b-v2",
            "jackaduma/SecRoBERTa",
            "pszemraj/led-large-book-summary",
            "Open-Orca/OpenOrca-Platypus2-13B",
            "codellama/CodeLlama-13b-hf",
            "knkarthick/MEETING_SUMMARY",
            "Helsinki-NLP/opus-mt-vi-en",
            "ai-forever/ruBert-base",
            "UBC-NLP/MARBERT",
            "ku-nlp/deberta-v2-base-japanese-char-wwm",
            "cmarkea/distilcamembert-base",
            "google/electra-base-generator",
            "TheBloke/Llama-2-13B-fp16",
            "explosion-testing/llama2-kv-sharing",
            "olm/olm-roberta-base-dec-2022",
            "chavinlo/alpaca-native",
            "microsoft/MiniLM-L12-H384-uncased",
            "OpenAssistant/oasst-sft-1-pythia-12b",
            "philschmid/BERT-Banking77"
        ],
        "1": [
            "mosaicml/mpt-7b-instruct",
            "distilbert-base-uncased-distilled-squad",
            "michiyasunaga/BioLinkBERT-base",
            "Qwen/Qwen-7B-Chat",
            "finiteautomata/beto-sentiment-analysis",
            "nlpaueb/legal-bert-base-uncased",
            "tiiuae/falcon-40b",
            "NousResearch/Yarn-Llama-2-7b-64k",
            "TheBloke/MythoMax-L2-13B-GPTQ",
            "Helsinki-NLP/opus-mt-en-ROMANCE",
            "climatebert/distilroberta-base-climate-detector",
            "ckiplab/albert-tiny-chinese-ner",
            "stanfordnlp/backpack-gpt2",
            "KoboldAI/GPT-NeoX-20B-Erebus",
            "shibing624/chinese-alpaca-plus-13b-hf",
            "TheBloke/Llama-2-13B-Chat-fp16",
            "huggyllama/llama-13b",
            "consciousAI/question-answering-roberta-base-s-v2",
            "lmsys/vicuna-7b-v1.5-16k",
            "facebook/wmt19-en-ru",
            "Helsinki-NLP/opus-mt-zh-de",
            "Salesforce/codegen2-1B",
            "NousResearch/GPT4-x-Vicuna-13b-fp16",
            "LinkSoul/Chinese-Llama-2-7b",
            "TheBloke/chronos-hermes-13B-GPTQ",
            "dandelin/vilt-b32-mlm",
            "EleutherAI/pythia-1b-deduped",
            "codellama/CodeLlama-34b-Python-hf"
        ],
        "2": [
            "PascalNotin/Tranception_Small",
            "lmsys/vicuna-7b-v1.1",
            "tiiuae/falcon-40b-instruct",
            "ainize/kobart-news",
            "roberta-large-mnli",
            "lmsys/vicuna-7b-v1.5",
            "mrm8488/bert-spanish-cased-finetuned-ner",
            "rinna/japanese-roberta-base",
            "uer/roberta-base-chinese-extractive-qa",
            "citizenlab/twitter-xlm-roberta-base-sentiment-finetunned",
            "TheBloke/llama-2-70b-Guanaco-QLoRA-GPTQ",
            "facebook/esm1v_t33_650M_UR90S_4",
            "facebook/nllb-200-distilled-1.3B",
            "microsoft/mpnet-base",
            "uer/gpt2-chinese-cluecorpussmall",
            "neulab/codebert-java",
            "Luyu/co-condenser-marco",
            "HuggingFaceH4/tiny-random-LlamaForCausalLM",
            "nickmuchi/finbert-tone-finetuned-fintwitter-classification",
            "codellama/CodeLlama-34b-hf",
            "microsoft/graphcodebert-base",
            "lucadiliello/BLEURT-20",
            "mosaicml/mpt-7b-8k-chat",
            "mesolitica/finetune-translation-t5-super-super-tiny-standard-bahasa-cased",
            "yiyanghkust/finbert-fls",
            "IlyaGusev/mbart_ru_sum_gazeta",
            "explosion-testing/bert-test",
            "xlm-roberta-large-finetuned-conll03-german"
        ],
        "3": [
            "t5-base",
            "EleutherAI/gpt-neo-125m",
            "cl-tohoku/bert-base-japanese-whole-word-masking",
            "pythainlp/thainer-corpus-v2-base-model",
            "roberta-large-openai-detector",
            "google/pegasus-xsum",
            "Salesforce/xgen-7b-8k-inst",
            "dominguesm/legal-bert-ner-base-cased-ptbr",
            "aubmindlab/bert-base-arabertv02",
            "StanfordAIMI/stanford-deidentifier-only-i2b2",
            "Hello-SimpleAI/chatgpt-qa-detector-roberta",
            "textattack/bert-base-uncased-SST-2",
            "beomi/KoAlpaca-Polyglot-12.8B",
            "hfl/chinese-macbert-base",
            "KoboldAI/OPT-13B-Erebus",
            "rinna/bilingual-gpt-neox-4b-instruction-sft",
            "Austism/chronos-hermes-13b-v2",
            "TheBloke/airoboros-l2-70B-gpt4-1.4.1-GPTQ",
            "stabilityai/stablecode-instruct-alpha-3b",
            "line-corporation/japanese-large-lm-3.6b",
            "lordtt13/emo-mobilebert",
            "savasy/bert-base-turkish-sentiment-cased",
            "ehartford/WizardLM-1.0-Uncensored-Llama2-13b",
            "VMware/open-llama-7b-v2-open-instruct",
            "NousResearch/Nous-Hermes-llama-2-7b",
            "georgesung/llama2_7b_chat_uncensored",
            "ichitaka/falcon-40b-instruct-8bit",
            "decapoda-research/llama-65b-hf"
        ],
        "4": [
            "t5-small",
            "gpt2-medium",
            "cross-encoder/ms-marco-MiniLM-L-4-v2",
            "deepset/bert-large-uncased-whole-word-masking-squad2",
            "HuggingFaceM4/tiny-random-LlamaForCausalLM",
            "hfl/chinese-roberta-wwm-ext",
            "czurita/nsql-llama-2-7B-sharded-bf16-2GB",
            "anas-awadalla/mpt-1b-redpajama-200b",
            "bert-base-german-cased",
            "sdadas/polish-roberta-large-v2",
            "lmsys/vicuna-13b-v1.5",
            "KoboldAI/OPT-6.7B-Erebus",
            "textattack/bert-base-uncased-STS-B",
            "yarongef/DistilProtBert",
            "cardiffnlp/twitter-xlm-roberta-base",
            "bigcode/starcoderbase",
            "reciprocate/gpt-j_rm_format-oa",
            "nghuyong/ernie-3.0-base-zh",
            "alvaroalon2/biobert_diseases_ner",
            "microsoft/infoxlm-base",
            "microsoft/codebert-base-mlm",
            "jondurbin/airoboros-l2-13b-gpt4-m2.0",
            "bhadresh-savani/roberta-base-emotion",
            "TheBloke/Wizard-Vicuna-30B-Uncensored-GPTQ",
            "rinna/japanese-gpt-neox-3.6b",
            "google/bigbird-pegasus-large-bigpatent",
            "TheBloke/Llama-2-13B-chat-GGML",
            "microsoft/deberta-v2-xxlarge"
        ]
    },
    "test-southafricanorth": {
        "0": [
            "ProsusAI/finbert",
            "distilbert-base-cased",
            "databricks/dolly-v2-3b",
            "Davlan/bert-base-multilingual-cased-ner-hrl",
            "hf-internal-testing/tiny-random-BloomForCausalLM",
            "TheBloke/Llama-2-7b-Chat-GPTQ",
            "stabilityai/StableBeluga-7B",
            "LinkSoul/Chinese-LLaVA-Baichuan",
            "textattack/roberta-base-CoLA",
            "alvaroalon2/biobert_chemical_ner",
            "arpanghoshal/EkmanClassifier",
            "NousResearch/Llama-2-7b-chat-hf",
            "edumunozsala/llama-2-7b-int4-python-code-20k",
            "togethercomputer/LLaMA-2-7B-32K",
            "databricks/dolly-v2-7b",
            "Helsinki-NLP/opus-mt-hu-en",
            "monologg/biobert_v1.1_pubmed",
            "padmajabfrl/Gender-Classification",
            "studio-ousia/luke-base",
            "TurkuNLP/bert-base-finnish-cased-v1",
            "castorini/afriberta_large",
            "wietsedv/bert-base-dutch-cased",
            "cyberagent/open-calm-small",
            "liuhaotian/LLaVA-Lightning-MPT-7B-preview",
            "michellejieli/NSFW_text_classifier",
            "VMware/open-llama-7b-open-instruct",
            "OpenAssistant/falcon-40b-sft-top1-560",
            "KoboldAI/GPT-Neo-2.7B-Shinen"
        ],
        "1": [
            "bigscience/bloom-560m",
            "cross-encoder/ms-marco-MiniLM-L-12-v2",
            "Helsinki-NLP/opus-mt-de-en",
            "meta-llama/Llama-2-70b-chat-hf",
            "hf-internal-testing/tiny-random-GPT2LMHeadModel",
            "staka/fugumt-ja-en",
            "blanchefort/rubert-base-cased-sentiment",
            "nateraw/bert-base-uncased-emotion",
            "EleutherAI/pythia-70m",
            "ku-nlp/deberta-v2-base-japanese",
            "IDEA-CCNL/Wenzhong-GPT2-110M",
            "Qwen/Qwen-VL-Chat",
            "sshleifer/tiny-distilbert-base-cased-distilled-squad",
            "Mizuiro-sakura/luke-japanese-large-sentiment-analysis-wrime",
            "microsoft/deberta-base-mnli",
            "tomh/toxigen_hatebert",
            "Helsinki-NLP/opus-mt-tc-big-tr-en",
            "bigscience/bloomz-3b",
            "qanastek/51-languages-classifier",
            "tuner007/pegasus_summarizer",
            "TheBloke/falcon-7b-instruct-GPTQ",
            "Helsinki-NLP/opus-mt-en-ro",
            "TheBloke/WizardLM-70B-V1.0-GPTQ",
            "pszemraj/led-base-book-summary",
            "arampacha/roberta-tiny",
            "Helsinki-NLP/opus-mt-sq-en",
            "fnlp/moss-base-7b",
            "TheBloke/llama2_7b_chat_uncensored-GPTQ"
        ],
        "2": [
            "xlm-roberta-large",
            "bert-large-uncased",
            "ipuneetrathore/bert-base-cased-finetuned-finBERT",
            "meta-llama/Llama-2-13b-chat-hf",
            "Vamsi/T5_Paraphrase_Paws",
            "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis",
            "IMSyPP/hate_speech_it",
            "KoboldAI/OPT-6.7B-Nerybus-Mix",
            "PAIXAI/Astrid-1B",
            "kontur-ai/sbert_punc_case_ru",
            "Davlan/afro-xlmr-large-61L",
            "cross-encoder/stsb-roberta-base",
            "facebook/bart-large-xsum",
            "cambridgeltl/sst_mobilebert-uncased",
            "EleutherAI/polyglot-ko-5.8b",
            "tiiuae/falcon-rw-1b",
            "internlm/internlm-7b",
            "Davlan/xlm-roberta-large-ner-hrl",
            "qanastek/pos-french-camembert",
            "akreal/tiny-random-LlamaForCausalLM",
            "h2oai/h2ogpt-oig-oasst1-512-6_9b",
            "NumbersStation/nsql-llama-2-7B",
            "bigcode/tiny_starcoder_py",
            "KoboldAI/GPT-Neo-2.7B-Horni",
            "TheBloke/Llama-2-7B-fp16",
            "hf-internal-testing/tiny-random-bloom",
            "Helsinki-NLP/opus-mt-en-sk",
            "oliverguhr/fullstop-punctuation-multilingual-base"
        ],
        "3": [
            "baichuan-inc/Baichuan-13B-Chat",
            "cerebras/btlm-3b-8k-base",
            "Helsinki-NLP/opus-mt-es-en",
            "seyonec/ChemBERTa-zinc-base-v1",
            "oliverguhr/fullstop-punctuation-multilang-large",
            "microsoft/deberta-v3-large",
            "klue/roberta-large",
            "codellama/CodeLlama-34b-Instruct-hf",
            "philschmid/distilbert-onnx",
            "ahotrod/albert_xxlargev1_squad2_512",
            "deepset/gbert-large",
            "fxmarty/tiny-testing-gpt2-remote-code",
            "cardiffnlp/twitter-roberta-base-emotion",
            "facebook/opt-66b",
            "facebook/esm2_t12_35M_UR50D",
            "openlm-research/open_llama_7b",
            "huggyllama/llama-30b",
            "medicalai/ClinicalBERT",
            "facebook/esm2_t30_150M_UR50D",
            "akreal/tiny-random-BloomForCausalLM",
            "EleutherAI/pythia-12b",
            "dennlinger/bert-wiki-paragraphs",
            "matthewburke/korean_sentiment",
            "TheBloke/orca_mini_v3_70B-GPTQ",
            "bergum/xtremedistil-l6-h384-go-emotion",
            "stabilityai/stablecode-completion-alpha-3b-4k",
            "allenai/ivila-row-layoutlm-finetuned-s2vl-v2",
            "facebook/xglm-7.5B"
        ],
        "4": [
            "ckiplab/bert-base-chinese-ner",
            "vblagoje/bert-english-uncased-finetuned-pos",
            "gpt2-large",
            "amazon/FalconLite",
            "naver/splade-cocondenser-ensembledistil",
            "microsoft/deberta-v2-xlarge",
            "bigscience/bloomz-7b1",
            "Helsinki-NLP/opus-mt-fi-en",
            "huggyllama/llama-65b",
            "trl-internal-testing/dummy-GPT2-correct-vocab",
            "Hello-SimpleAI/chatgpt-qa-detector-roberta-chinese",
            "arpanghoshal/EmoRoBERTa",
            "EleutherAI/pythia-2.8b",
            "deepset/deberta-v3-large-squad2",
            "Helsinki-NLP/opus-mt-da-de",
            "thatdramebaazguy/roberta-base-squad",
            "bigscience/bloom",
            "anas-awadalla/mpt-7b",
            "ehsanaghaei/SecureBERT",
            "petals-team/falcon-rw-1b",
            "Helsinki-NLP/opus-mt-de-ZH",
            "TheBloke/WizardLM-30B-Uncensored-GPTQ",
            "KoboldAI/OPT-13B-Nerybus-Mix",
            "jarvisx17/japanese-sentiment-analysis",
            "h2oai/h2ogpt-4096-llama2-70b-chat",
            "bdotloh/distilbert-base-uncased-empathetic-dialogues-context",
            "sshleifer/distilbart-cnn-6-6",
            "cyberagent/open-calm-3b"
        ]
    }
}