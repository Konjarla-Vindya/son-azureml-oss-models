import os
import json
from urllib.request import urlopen

def fetch_models_data(url):
    try:
        response = urlopen(url)
        data_json = json.loads(response.read())
        return data_json
    except Exception as e:
        print(f"Error fetching data: {e}")
        return []

def generate_workflow_yaml(original_yaml_file, output_directory, model_name):
    try:
        with open(original_yaml_file, 'r') as f:
            yaml_content = f.read()

        yaml_content = yaml_content.replace('test_model_name: bert-base-uncased', f'test_model_name: {model_name}')
        yaml_content = yaml_content.replace('test_queue: model_with_static_library', f'test_queue: {model_name}_queue')

        generated_yaml_filename = f'{model_name}_workflow.yaml'
        generated_yaml_path = os.path.join(output_directory, generated_yaml_filename)

        with open(generated_yaml_path, 'w') as f:
            f.write(yaml_content)
        
        print(f"Generated YAML file: {generated_yaml_path}")
    except Exception as e:
        print(f"Error generating YAML for {model_name}: {e}")

def main():
    url = "https://huggingface.co/api/models"
    original_yaml_file = "../../.github/workflows/1kmodels.yml"
    output_directory = '../../src/1kmodelsYaml' 
    list1 = ["fill-mask", "translation", "text-generation", "token-classification", "summarization", "text-classification", "question-answering"]

    os.makedirs(output_directory, exist_ok=True)

    data_json = fetch_models_data(url)
    if not data_json:
        return
    
    df = pd.DataFrame(data_json)
    df2 = df.loc[df["pipeline_tag"].isin(list1), ["id", "pipeline_tag", "downloads"]].sort_values(by="downloads", ascending=False).head(1000)
    model_names = df2["id"].head(50)

    for model_name in model_names:
        generate_workflow_yaml(original_yaml_file, output_directory, model_name)

    print("Generated YAML files for selected models.")

if __name__ == "__main__":
    main()
